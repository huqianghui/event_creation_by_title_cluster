{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, download_loader, SimpleDirectoryReader, LLMPredictor, PromptHelper,ServiceContext\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import openai\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from llama_index import LangchainEmbedding\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openaidemo-hu.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"XXX\"\n",
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_base = \"https://openaidemo-hu.openai.azure.com/\"\n",
    "openai.api_key = \"XXX\"\n",
    "\n",
    "davinci = AzureOpenAI(\n",
    "    deployment_name=\"text-davinci-003\",\n",
    "    model_name=\"text-davinci-003\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "gpt4 = AzureChatOpenAI(\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    deployment_name=\"gpt4\",\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type=openai.api_type,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1, openai_api_version=\"2023-05-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取CSV文件\n",
    "data = pd.read_csv('sample_data_title_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorityEntityData = pd.read_csv(\"priority_entity.csv\")\n",
    "priorityEntityData['similarity'] = priorityEntityData['priority_entity'].apply(lambda x: embeddings.embed_query(x))\n",
    "\n",
    "priorityEntityData.to_csv(\"priority_entity_embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorityEntityDataEmbedding = pd.read_csv('priority_entity_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity_calculation(x_vector, y_vector):\n",
    "    # 计算点积\n",
    "    dot_product = np.dot(x_vector, y_vector)\n",
    "    # 计算向量的范数（长度）\n",
    "    norm_array1 = np.linalg.norm(x_vector)\n",
    "    norm_array2 = np.linalg.norm(y_vector)\n",
    "    return dot_product / (norm_array1 * norm_array2)\n",
    "\n",
    "def convet_to_float_array(input: str) -> np.array:\n",
    "    values_str = input.strip('[]')\n",
    "    values_list = values_str.split(',')\n",
    "    # 将字符串列表转换为浮点数数组\n",
    "    float_array = np.array([float(value) for value in values_list])\n",
    "    return float_array\n",
    "\n",
    "def tilte_query_cosine_similarity_calculation(input_vector_str:str,query_vector):\n",
    "    float_array_result= convet_to_float_array(input_vector_str)\n",
    "    return cosine_similarity_calculation(query_vector,float_array_result)\n",
    "\n",
    "for index,record in priorityEntityDataEmbedding.iterrows():\n",
    "    \n",
    "    column_name = \"similarity\" + \"_\" + str(record[\"No.\"])\n",
    "    query_vector = convet_to_float_array(record[\"similarity\"])\n",
    "    data[column_name] = data['title_embedding'].apply(lambda x: tilte_query_cosine_similarity_calculation(x,query_vector))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "data.to_csv('sample_data_title_embedding_priorityEntity_similar.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样地，计算出来了余弦相似性便可以取得，余弦阈值的所有记录，同样用0.85为例子（经验值，看到几个标题大概是0.86,0.87左右，所以0.9不合适）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample_data_title_embedding_priorityEntity_similar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 小米第5年上榜世界500强 雷军感谢用户信任\\n 2. 雷军：小米连续5年上榜财富世界500强\\n 3. 大行评级丨瑞银：予小米16港元目标价 为中国智能手机领域首选\\n 4. 大行评级丨瑞银：予小米16港元目标价 为中国智能手机领域首选\\n ',\n",
       " '1. 那个能打的蔚来，又回来了\\n ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 选择包含'similarity'的列\n",
    "similarity_cols = data.filter(like='similarity').columns\n",
    "\n",
    "priorityEntityEventSourcelist = []\n",
    "# 选择值大于0.8的所有记录\n",
    "for col in similarity_cols:\n",
    "    matched_title_df = data.loc[data[col].gt(0.85)]\n",
    "    num =0\n",
    "    eventSource=\"\"\n",
    "    for index,record in matched_title_df.iterrows():\n",
    "        num+=1\n",
    "        rowNo = str(num) + \". \"\n",
    "        eventSource = eventSource + rowNo + record[\"title\"] + \"\\n \"\n",
    "    priorityEntityEventSourcelist.append(eventSource)\n",
    "\n",
    "display(priorityEntityEventSourcelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小米连续五年跻身世界500强，瑞银给予16港元目标价。\n",
      "蔚来强势回归，再度引领竞争。\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=('''You are a financial journalist who, based on the financial news headlines provided by the user, Summarize into a simple, clear, easily understandable sentence that grabs attention in fewer than 15 words. \n",
    "            if the language of headlines is Chinses,please answer in Chinese. ''')\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"The corresponding financial news headlines are as follows: {event_Source}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for priorityEntityEventSource in priorityEntityEventSourcelist:\n",
    "    eventFinal = gpt4(template.format_messages(event_Source=priorityEntityEventSource)).content\n",
    "    print(eventFinal)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
